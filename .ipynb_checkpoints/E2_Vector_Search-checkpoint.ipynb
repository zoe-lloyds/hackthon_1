{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9dcb1bde-3ac1-42ba-ad90-bc93df01c0f8",
   "metadata": {},
   "source": [
    "# Embeddings - Vertex AI Vector Search\n",
    "\n",
    "### Semantic Search Using Embeddings and Vertex AI Vector Search (Formerly Matching Engine)\n",
    "\n",
    "- Semantic search is a type of search that uses the meaning of words and phrases to find relevant results.\n",
    "- In this tutorial, we will demonstrate how to do semantic search with embeddings generated from the news text using vector search`\n",
    "- Vertex AI Vector Search (formerly known as Matching Engine) is a vector database, which can find the most similar vectors from over a billion vectors. Matching Engine's ANN service can serve similarity-matching queries at high queries per second (QPS).\n",
    "\n",
    "This pattern is more appropriate for larger datasets and production deployments. For demonstrating the full workflow and explanation, a small dataset is pre-processed locally and uploaded to a storage bucket in this example. In a larger or production deployment, the embedding generation and storage can be done separately and Vector Search provides db update strategies as described later in this notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc3920ce-2421-4026-a142-db29cd968b83",
   "metadata": {},
   "source": [
    "## Install Vertex LLM SDK\n",
    "\n",
    "Install required libraries and initialises the Vertex AI SDK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "484703ed-180e-4dfa-a59a-6845b36c809b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install Required Libraries\n",
    "!pip3 install \"google-cloud-aiplatform>=1.25\" \"shapely<2.0.0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb177979-b284-456a-ba78-6a8c3e3870bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Vertex AI SDK\n",
    "PROJECT_ID = !gcloud config get project\n",
    "PROJECT_ID = PROJECT_ID.n\n",
    "LOCATION = \"europe-west2\"\n",
    "LOCATION_DEPLOY = \"europe-west2\" #Location to deploy GCP resources\n",
    "\n",
    "import vertexai\n",
    "from google.cloud import aiplatform\n",
    "\n",
    "vertexai.init(project=PROJECT_ID, location=LOCATION)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dec92d49-de0b-47c4-9071-aa74c2d8c062",
   "metadata": {},
   "source": [
    "## Import TextEmbeddingModel\n",
    "\n",
    "**Available models as of Sep 2023:**\n",
    "| Models | Description\n",
    "| :- | :- |\n",
    "| textembedding-gecko@001 | stable |\n",
    "| textembedding-gecko@latest | public preview: an embeddings model with enhanced AI quality |\n",
    "| textembedding-gecko-multilingual@latest | public preview: an embeddings model designed to use a wide range of non-English languages. |\n",
    "\n",
    "\n",
    "Further documentation on available models can be found here: https://cloud.google.com/vertex-ai/docs/generative-ai/embeddings/get-text-embeddings#generative-ai-get-text-embedding-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcb9c36d-f0a3-47d2-9ed5-bc99fad4c23c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from vertexai.preview.language_models import TextEmbeddingModel\n",
    "\n",
    "model = TextEmbeddingModel.from_pretrained(\"textembedding-gecko@001\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b997769-ceaf-4837-afe6-fffae3e4d8ab",
   "metadata": {},
   "source": [
    "## Import Required Packages\n",
    "\n",
    "Outputs with regard to Tensorflow can be ignored as this is caused by this notebook being CPU only, a GPU is not required for this demonstration.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51e7ebba-ad16-43db-a36d-30cecd8d1316",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import time\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47573a7f-5af5-4163-af8f-4a7462ed14a1",
   "metadata": {},
   "source": [
    "## Create Embedding Dataset.\n",
    "\n",
    "The dataset is solely to demonstrate the use of the Text Embedding API with a vector database. It is not intended to be used for any other purpose, such as evaluating models. The dataset is small and does not represent a comprehensive sample of all possible text.\n",
    "\n",
    "The following command copies the data json file from a google storage bucket, the data is stored locally within the notebook for use. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec12607e-a969-44a9-a486-db32303dfa09",
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir -p datasets\n",
    "!gsutil cp gs://gen-ai-{PROJECT_ID}-bucket/embeddings/data/google_embeddings_dataset.jsonl ./datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b676dbc8-7865-41dc-b45f-c5c75cff1f4f",
   "metadata": {},
   "source": [
    "### Load data.json as a python list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d229a49b-8cd3-4e77-a34e-abb269a2f8a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "records = []\n",
    "with open(\"./datasets/google_embeddings_dataset.jsonl\") as f:\n",
    "    for line in f:\n",
    "        record = json.loads(line)\n",
    "        records.append(record)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1c2781e-3d95-44b4-9745-63366fcef6b6",
   "metadata": {},
   "source": [
    "### Peek at the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abcd3dbc-cece-4b58-8aa7-c599024acf56",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(records)\n",
    "df.head(50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd147c2f-6653-48c2-ad64-df8255b2aba0",
   "metadata": {},
   "source": [
    "### Get embeddings from the Google Embedding Model\n",
    "\n",
    "The following code sends a request to the embedding model api to get the embedding vector for each entry in the dataset and stores it in a Python DataFrame.\n",
    "\n",
    "The number of dimensions of the embedding vectors is 768 for the text-embedding gecko model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f732506-1c2a-4117-a9b6-132e49ecc601",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_embedding(text):\n",
    "    get_embedding.counter += 1\n",
    "    try:\n",
    "        if get_embedding.counter % 100 == 0:\n",
    "            time.sleep(3)\n",
    "        return model.get_embeddings([text])[0].values #Send request to embedding model\n",
    "    except:\n",
    "        return []\n",
    "\n",
    "\n",
    "get_embedding.counter = 0\n",
    "\n",
    "# This may take several minutes to complete.\n",
    "df[\"embedding\"] = df[\"textContent\"].apply(lambda x: get_embedding(x))\n",
    "\n",
    "# Convert the embeddings into a Python list \n",
    "embeddings_list = df['embedding'].values.tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "705fd1ff-4a74-4fa9-a8cf-9661608cf816",
   "metadata": {},
   "source": [
    "## Using Vertex AI Vector Search Approximate Nearest Neighbour (ANN) Service\n",
    "\n",
    "Vertex AI Vector Search (formerly known as Matching Engine) is a vector database, which can find the most similar vectors from over a billion vectors. Matching Engine's ANN service can serve similarity-matching queries at high queries per second (QPS).\n",
    "\n",
    "Further Details and Documentation: https://cloud.google.com/vertex-ai/docs/matching-engine/ann-service-overview\n",
    "\n",
    "**Terminology**\n",
    "- **Index:** A collection of vectors deployed together for similarity search. Vectors can be added to an index or removed from an index. Similarity search queries are issued to a specific index and will search over the vectors in that index.\n",
    "- **Recall:** The percentage of true nearest neighbors returned by the index. For example, if a nearest neighbor query for 20 nearest neighbors returned 19 of the \"ground truth\" nearest neighbors, the recall is 19/20x100 = 95%.\n",
    "- **Restricts:** Functionality to \"restrict\" searches to a subset of the index by using Boolean rules."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23c542d5-3021-4f24-9b39-9bd7b5e6163f",
   "metadata": {},
   "source": [
    "### Generate Embedding File\n",
    "\n",
    "\n",
    "This function converts the embedding and saves it into a json file format usable with matching engine in the following format. \n",
    "- Encode the file using UTF-8.\n",
    "- Make each line a valid JSON object to be interpreted as a record.\n",
    "- Include in each record a field named id that requires a valid UTF-8 string that is the ID of the vector.\n",
    "- Include in each record a field named embedding that requires an array of numbers. This is the feature vector.\n",
    "\n",
    "Other file formats can be found here: https://cloud.google.com/vertex-ai/docs/matching-engine/match-eng-setup/format-structure#json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bba45144-ba7e-4b76-a13c-26cae65f6ab5",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"./datasets/vector_search_dataset.json\", \"w\") as f:\n",
    "    for i in range(len(embeddings_list)):\n",
    "        f.write('{\"id\":\"' + str(i) + '\",')\n",
    "        f.write('\"embedding\":[' + \",\".join(str(x) for x in embeddings_list[i]) + \"]}\")\n",
    "        f.write(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e04efd0b-245a-4f3c-90b2-6443c235f4b4",
   "metadata": {},
   "source": [
    "### Copy Dataset to Storage Bucket\n",
    "The following command copies the data file to a cloud storage bucket. Folder structure documentation: https://cloud.google.com/vertex-ai/docs/matching-engine/match-eng-setup/format-structure#input_directory_structure\n",
    "\n",
    "Supported Update Methods:\n",
    "- **Batch:** To update the content of an existing Index, use the IndexService.UpdateIndex method.\n",
    "- **Streaming:** With Streaming Updates, you can update and query your index within a few seconds. At this time, you can't use Streaming Updates on an existing index, you must create a new index.\n",
    "\n",
    "Documentation: https://cloud.google.com/vertex-ai/docs/matching-engine/update-rebuild-index#update_index_content_with_batch_updates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd50467c-d690-4e12-85eb-644aa87dc125",
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir -p datasets\n",
    "!gsutil copy ./datasets/vector_search_dataset.json gs://gen-ai-{PROJECT_ID}-bucket/embeddings/vs_root/vector_search_dataset.json"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "026abd3e-27e5-4df2-b23a-d2625eda989e",
   "metadata": {},
   "source": [
    "### Create an Index\n",
    "\n",
    "Details on configuration parameters can be found here: https://cloud.google.com/vertex-ai/docs/matching-engine/configuring-indexes\n",
    "\n",
    "**It can take up to 30 minutes to deploy.**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9a65998-92a3-4d9c-b729-92f44352a86a",
   "metadata": {},
   "outputs": [],
   "source": [
    "DIMENSIONS = 768\n",
    "GS_URI = \"gs://gen-ai-%s-bucket/embeddings/vs_root/\" % PROJECT_ID\n",
    "\n",
    "gen_ai_index = aiplatform.MatchingEngineIndex.create_tree_ah_index(\n",
    "    display_name=\"Gen AI Index\",\n",
    "    contents_delta_uri=GS_URI,\n",
    "    dimensions=DIMENSIONS,\n",
    "    approximate_neighbors_count=5,\n",
    "    distance_measure_type=\"DOT_PRODUCT_DISTANCE\",\n",
    "    leaf_node_embedding_count=10,\n",
    "    leaf_nodes_to_search_percent=80,\n",
    "    description=\"Example Index for Gen AI Playpen\",\n",
    "    location=LOCATION_DEPLOY\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90580dc3-0ea9-490a-8dd9-bae9d6eb1d0f",
   "metadata": {},
   "source": [
    "### Create an Index Endpoint\n",
    "\n",
    "The following function is used to create an index endpoint, this allows for queries to be sent to the index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "879730f0-08e1-43cb-8e9d-84ed5ed21eb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "gen_ai_index_endpoint = aiplatform.MatchingEngineIndexEndpoint.create(\n",
    "    display_name=\"Gen AI Index Endpoint\",\n",
    "    description=\"Example Index for Gen AI Playpen\",\n",
    "    public_endpoint_enabled=True,\n",
    "    location=LOCATION_DEPLOY\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c676aad-7a40-4eda-a707-b05826116648",
   "metadata": {},
   "source": [
    "### Deploy the Index to the Index-Endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbb12ba9-daec-4447-bbc4-5f515eeed6de",
   "metadata": {},
   "outputs": [],
   "source": [
    "gen_ai_index_endpoint = gen_ai_index_endpoint.deploy_index(\n",
    "    index=gen_ai_index, deployed_index_id=\"gen_ai_deployed_index\",\n",
    "    machine_type=\"e2-standard-16\",\n",
    "    min_replica_count=1,\n",
    "    max_replica_count=1\n",
    ")\n",
    "\n",
    "gen_ai_index_endpoint.deployed_indexes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c846460-0cdb-4450-890e-0750be664d72",
   "metadata": {},
   "source": [
    "### Additional Functions:\n",
    "Uncomment, replace the relevant project, region and ids to retrieve indexes and index endpoints. The ids can be found on the cloud console under Vertex AI and Vector Search on the left bar. This is useful as obtaining the index objects allow for functions on them (such as delete or query) if the notebook kernels etc. have been reset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed7f36ad-baf8-4840-b54f-4f3ad6ac483d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# gen_ai_index_endpoint = aiplatform.MatchingEngineIndexEndpoint(\n",
    "#     index_endpoint_name=\"projects/playpen-b90269/locations/europe-west2/indexEndpoints/7664563615831162880\"\n",
    "# )\n",
    "\n",
    "# gen_ai_index = aiplatform.MatchingEngineIndex(\n",
    "#     index_name=\"projects/replace_with_project_id/locations/europe-west2/indexes/replace_with_id\"\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "887be221-5fb5-4c63-8cff-015ea87337ee",
   "metadata": {},
   "source": [
    "### Create Online Queries\n",
    "\n",
    "Pre-define function that generates an embedding for an input prompt using the embeddings-gecko model and performs a search."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "671ba8a5-b52f-4f94-9763-436714450fda",
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_NEIGHBOURS = 3 #Number of neighbours from query\n",
    "\n",
    "def search(input):\n",
    "    embedding_vec =  model.get_embeddings([input])[0].values #Send request to embedding model to generate the embedding vector\n",
    "    \n",
    "    #find neighbours using vector search\n",
    "    neighbours = gen_ai_index_endpoint.find_neighbors(\n",
    "        deployed_index_id=\"gen_ai_deployed_index\",\n",
    "        queries=[embedding_vec],\n",
    "        num_neighbors=NUM_NEIGHBOURS,\n",
    "    )[0]\n",
    "    \n",
    "    for nb in neighbours:\n",
    "        print(\"id: \" + nb.id + \" | text: \" + df.iloc[int(nb.id)][\"textContent\"] + \" | dist: \" + str(nb.distance)) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54040490-9889-499d-94a6-83529908d956",
   "metadata": {},
   "source": [
    "### Example Queries\n",
    "\n",
    "If you face an openssl error, please wait up to 5 minutes for the endpoint to finish deploying."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebf879ce-1927-48f6-9b39-4da8947fca6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "search(\"tell me about shark or animal\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed4eca81-cffa-4f5e-9851-780ecdc6ccf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "search(\"tell me about an important moment or event in your life\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85b9abd4-ae9f-4eb4-a0b8-97575d670b5f",
   "metadata": {},
   "source": [
    "### Clean Up Resources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59026bc8-9b3c-4bcd-b1f6-2f16de1e12c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "gen_ai_index_endpoint.undeploy_all()\n",
    "gen_ai_index_endpoint.delete() #index endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "615d189e-2066-4719-9d27-1fb8a18ce1cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "gen_ai_index.delete()"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "tf2-cpu.2-11.m112",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-cpu.2-11:m112"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
