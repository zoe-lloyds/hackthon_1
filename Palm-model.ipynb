{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a36e3219-1cc8-4c0d-80f8-66a722886dd1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting package metadata (current_repodata.json): done\n",
      "Solving environment: failed with initial frozen solve. Retrying with flexible solve.\n",
      "Collecting package metadata (repodata.json): done\n",
      "Solving environment: failed with initial frozen solve. Retrying with flexible solve.\n",
      "Solving environment: - \n",
      "Found conflicts! Looking for incompatible packages.\n",
      "This can take several minutes.  Press CTRL-C to abort.\n",
      "Examining conflict for certifi google-cloud-core decorator importlib-metadata / "
     ]
    }
   ],
   "source": [
    "conda install python=3.8.16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8d6252c8-ab57-44ad-8098-3f9f844d4710",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-01 12:18:54.936527: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-12-01 12:18:57.265106: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda/lib64:/usr/local/nccl2/lib:/usr/local/cuda/extras/CUPTI/lib64\n",
      "2023-12-01 12:18:57.265352: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda/lib64:/usr/local/nccl2/lib:/usr/local/cuda/extras/CUPTI/lib64\n",
      "2023-12-01 12:18:57.265368: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "from vertexai.preview.language_models import ChatModel\n",
    "\n",
    "class PaLMWrapper:\n",
    "    def __init__(self):\n",
    "        self.chat_model = ChatModel.from_pretrained(\"chat-bison@001\")\n",
    "        self.parameters = {\n",
    "            \"temperature\": 0.2,\n",
    "            \"max_output_tokens\": 256,\n",
    "            \"top_p\": 0.95,\n",
    "        }\n",
    "    \n",
    "    def generate_response(self, context, message):\n",
    "        chat = self.chat_model.start_chat(context=context)\n",
    "        response = chat.send_message(message, **self.parameters)\n",
    "        return response.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "98a81fb2-61ed-42b5-a6ed-2709bfb98d6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "pw = PaLMWrapper()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "35650099-6484-483d-9f7d-2d0174721860",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Today in London, the weather is going to be cloudy with a high of 55 degrees Fahrenheit and a low of 45 degrees Fahrenheit. There is a 20% chance of rain.'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = pw.generate_response(context='you are a london weather forecaster', message='whats the weather like today')\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "539f7e2d-5465-45fc-bed6-8b7037ff8118",
   "metadata": {},
   "outputs": [],
   "source": [
    "# class VertexAIVectorStore:\n",
    "#     def __init__(self):\n",
    "        \n",
    "#         # god awful way of doing it, should be a config and passed through but oh well hacky hack\n",
    "#         self.gen_ai_index_endpoint = aiplatform.MatchingEngineIndexEndpoint(\n",
    "#             index_endpoint_name=\"projects/playpen-8d8611/locations/europe-west2/indexEndpoints/5891412000042385408\"\n",
    "#         )\n",
    "\n",
    "#         self.gen_ai_index = aiplatform.MatchingEngineIndex(\n",
    "#             index_name=\"projects/playpen-8d8611/locations/europe-west2/indexes/2680908415680643072\"\n",
    "#         )\n",
    "        \n",
    "#     def search(self, input, k=3):\n",
    "#         embedding_vec =  model.get_embeddings([input])[0].values #Send request to embedding model to generate the embedding vector\n",
    "\n",
    "#         #find neighbours using vector search\n",
    "#         neighbours = gen_ai_index_endpoint.find_neighbors(\n",
    "#             deployed_index_id=\"gen_ai_deployed_index\",\n",
    "#             queries=[embedding_vec],\n",
    "#             num_neighbors=k,\n",
    "#         )[0]\n",
    "\n",
    "#         for nb in neighbours:\n",
    "#             print(\"id: \" + nb.id + \" | text: \" + df.iloc[int(nb.id)][\"text\"] + \" | dist: \" + str(nb.distance)) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6881b24b-daaa-49df-9b3d-10f962e1ff74",
   "metadata": {},
   "outputs": [],
   "source": [
    "vai = VertexAIVectorStore()\n",
    "\n",
    "weather = vai.search(input='whats the weather like today')\n",
    "weather"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b29b2c57-c019-4edf-93d5-6b3ccdcc6301",
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'RetrievalQA' from 'langchain.chains' (/opt/conda/lib/python3.7/site-packages/langchain/chains/__init__.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m/var/tmp/ipykernel_7966/1819650081.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mlangchain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchains\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mRetrievalQA\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m: cannot import name 'RetrievalQA' from 'langchain.chains' (/opt/conda/lib/python3.7/site-packages/langchain/chains/__init__.py)"
     ]
    }
   ],
   "source": [
    "from operator import itemgetter\n",
    "\n",
    "vertex_store = VertexAIVectorStore()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6023d82d-35f0-401a-ac4e-ba4bf89368d9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "tf2-cpu.2-11.m112",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-cpu.2-11:m112"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
